= Architecture

Siren Federate is designed around the following core requirements:

* Low latency, real time interactive response – Siren Federate is designed to power ad hoc interactive, read only
queries such as those sent from Siren Investigate.
* Implementation of a fully featured relational algebra, capable of being extended for advanced join conditions, operations
and statistical optimizations.
* Flexible in-memory distributed computational framework.
* Horizontal scaling of fully distributed operations, leveraging all the available nodes in the cluster.
* Federated – capable of working on data that is not inside the cluster, for example via JDBC connections.

Siren Federate is based on the following high level architecture concepts:

* A coordinator node which is in charge of the query parsing, query planning and query execution. We are leveraging the
Apache Calcite engine to create a logical plan of the query, optimise the logical plan and execute a physical plan.
* A set of worker processes that are in charge of executing the physical operations. Depending on the type of physical
operation, a worker process is spawned on a per node or per shard basis.
* An in-memory distributed file system that is used by the worker nodes to exchange data, with a compact columnar data
representation optimized for analytical data processing, zero copy and zero data serialisation.

== Query Planning and Optimisation

The coordinator node is leveraging Apache Calcite for planning the job execution. A search request is first parsed
into an abstract syntax tree before being transformed into a logical relational plan. A set of rules will then be
applied to optimise the logical plan. We leverage both the Hep and Volcano engine to optimise the logical plan
using heuristic and statistical information. The logical plan is then transformed into a physical plan before being
executed.

The physical plan represents a tree of tasks to be executed. The coordinator will try to execute tasks concurrently
when possible. In the previous example, the two `Search/Project` tasks are executed concurrently, and the
`Hash Join` task is executed only after the completion of the two `Search/Project` tasks.

When handling a multi search request, each request will be planned separately, each one producing a physical plan.
However, before the execution of the physical plans, the planner will combine all the physical plans into a single
one, by mapping identical operations to one single task. We can see that as a step to fold multiple trees of tasks into
a single directed graph model, where overlapping operations across trees will become one single vertex in the graph.
This is useful to reuse computation across multiple requests.
